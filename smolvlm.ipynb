{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d30cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from PIL import Image\n",
    "# from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "# from transformers.image_utils import load_image\n",
    "\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # Load images\n",
    "# image = load_image(\"/home/chen/dev/Factory/img/BlueUp2.jpg\")\n",
    "\n",
    "# # Initialize processor and model\n",
    "# processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-256M-Instruct\")\n",
    "# model = AutoModelForVision2Seq.from_pretrained(\n",
    "#     \"HuggingFaceTB/SmolVLM-256M-Instruct\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     _attn_implementation=\"flash_attention_2\" if DEVICE == \"cuda\" else \"eager\",\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# # Create input messages\n",
    "# messages = [\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": [\n",
    "#             {\"type\": \"image\"},\n",
    "#             {\"type\": \"text\", \"text\": \"Can you describe this image?\"}\n",
    "#         ]\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# # Prepare inputs\n",
    "# prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "# inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "# inputs = inputs.to(DEVICE)\n",
    "\n",
    "# # Generate outputs\n",
    "# generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "# generated_texts = processor.batch_decode(\n",
    "#     generated_ids,\n",
    "#     skip_special_tokens=True,\n",
    "# )\n",
    "\n",
    "# print(generated_texts[0])\n",
    "# # \"\"\"\n",
    "# # Assistant: The image depicts a large, historic statue of liberty, located in New York City. The statue is a green, cylindrical structure with a human figure at the top, holding a torch. The statue is situated on a pedestal that resembles the statue of liberty, which is located on a small island in the middle of a body of water. The water surrounding the island is calm, reflecting the blue sky and the statue.\n",
    "# # In the background, there are several tall buildings, including the Empire State Building, which is visible in the distance. These buildings are made of glass and steel, and they are positioned in a grid-like pattern, giving them a modern look. The sky is clear, with a few clouds visible, indicating fair weather.\n",
    "# # The statue is surrounded by trees, which are green and appear to be healthy. There are also some small structures, possibly houses or buildings, visible in the distance. The overall scene suggests a peaceful and serene environment, typical of a cityscape.\n",
    "# # The image is taken during the daytime, likely during the day of the statue's installation. The lighting is bright, casting a strong shadow on the statue and the water, which enhances the visibility of the statue and the surrounding environment.\n",
    "# # To summarize, the image captures a significant historical statue of liberty, situated on a small island in the middle of a body of water, surrounded by trees and buildings. The sky is clear, with a few clouds visible, indicating fair weather. The statue is green and cylindrical, with a human figure holding a torch, and is surrounded by trees, indicating a peaceful and well-maintained environment. The overall scene is one of tranquility and historical significance.\n",
    "# # \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a53769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are a helpful assistant that can understand images and answer questions. Describe objects and their relative locations in details: \n",
      "Assistant: The image features a blue cube on a white surface. The cube is placed in the center of the image, with the top cube slightly tilted to the right. The cube is made of a shiny material, likely rubber, and has a smooth surface. The top cube is slightly larger than the bottom cube, and they are both placed on a white surface.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "\n",
    "model_path = \"HuggingFaceTB/SmolVLM2-256M-Video-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    _attn_implementation=\"flash_attention_2\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": \"/home/chen/dev/Factory/img/BlueUp1.jpg\"},\n",
    "            {\"type\": \"text\", \"text\": \"You are a helpful assistant that can understand images and answer questions. Describe objects and their relative locations in details: \"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=200)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "print(generated_texts[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e4b24bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are a helpful assistant that can understand images and answer questions. Describe objects and their relative locations in brief: \n",
      "Assistant: A blue cube and a green cube are placed on a white surface.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": \"/home/chen/dev/Factory/img/BlueUp1.jpg\"},\n",
    "            {\"type\": \"text\", \"text\": \"You are a helpful assistant that can understand images and answer questions. Describe objects and their relative locations in brief: \"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=15)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "print(generated_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46251f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Identify the green object and describe its environments. If any objects are blocking the path for a robotic arm to grasp it, provide a step-by-step strategy to pick up the green object safely.\n",
      "Assistant: The green object is a cube. It is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on a flat surface. The cube is placed on\n"
     ]
    }
   ],
   "source": [
    "user_prompt = (\n",
    "    \"Identify the green object and describe its environments. \"\n",
    "    \"If any objects are blocking the path for a robotic arm to grasp it, \"\n",
    "    \"provide a step-by-step strategy to pick up the green object safely.\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": \"/home/chen/dev/Factory/img/BlueUp1.jpg\"},\n",
    "            {\"type\": \"text\", \"text\": user_prompt},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=200)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "print(generated_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357f3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3de99e0d",
   "metadata": {},
   "source": [
    "# GPU Memory cost\n",
    "\n",
    "256M smolvlm bf16 1200 MB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
